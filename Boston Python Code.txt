# Import dependencies
import numpy as np
import pandas as pd
from sklearn.datasets import load_boston
import tensorflow as tf
import matplotlib.pyplot as plt
%matplotlib inline
import random

#Load Dataset
boston = load_boston()

# Seperate Data into Features and Labels and load them as a Pandas Dataframe
features_df = pd.DataFrame(np.array(boston.data), columns=[boston.feature_names])
features_df.head()
labels_df = pd.DataFrame(np.array(boston.target), columns=['labels'])
labels_df.head()
combined_data = pd.concat([features_df,labels_df], axis=1)
combined_data.head()

# Split data
from sklearn.model_selection import train_test_split
random.seed( 1000 )
X_train, X_test, y_train, y_test = train_test_split(features_df, labels_df, test_size=0.2)

# Scale Train data
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
X_train = pd.DataFrame(data=scaler.transform(X_train), columns=X_train.columns, index=X_train.index)
X_train = np.array(X_train)
y_train = np.array(y_train)
type(X_train), type(y_train)

# Scale Test data
scal = StandardScaler()
scal.fit(X_test)
X_test = pd.DataFrame(data=scal.transform(X_test), columns=X_test.columns, index=X_test.index)
X_test = np.array(X_test)
y_test = np.array(y_test)
type(X_test), type(y_test)

# Define Feature columns
features_df.columns

# Make Feature Columns
feat_cols = [tf.feature_column.numeric_column('x', shape=np.array(X_train).shape[1:])]

# Define Input Fuction
input_func = tf.estimator.inputs.numpy_input_fn({'x':X_train}, y_train, batch_size=1, num_epochs=2000, shuffle=True)

# Build the model
dnn_model = tf.estimator.DNNRegressor(hidden_units=[5,3],feature_columns=feat_cols, optimizer='Adam')
dnn_model.train(input_fn=input_func, steps=2000)

# Evaluate the model
dnn_model.evaluate(input_fn=eval_input_func)
predictions = dnn_model.predict(input_fn=eval_input_func)
pred = list(predictions)
predicted_vals = []
for pred in dnn_model.predict(input_fn=eval_input_func):
    predicted_vals.append(pred['predictions'])
print(predicted_vals)

# Performance Evaluation
from sklearn.metrics import mean_squared_error

# Calculate Mean Squared Error
mse = mean_squared_error(predicted_vals, y_test)
print('Mean Squared Error [DNNRegrssor]: ',mse)

# Improve the Performance by changing Parameters
dnn_model_imp = tf.estimator.DNNRegressor(hidden_units=[10,5,3],feature_columns=feat_cols, optimizer=tf.train.ProximalAdagradOptimizer(
      learning_rate=0.1,
      l1_regularization_strength=0.001
    ))
dnn_model_imp.train(input_fn=input_func, steps=2000)
dnn_model_imp.evaluate(input_fn=eval_input_func)
new_predictions = dnn_model_imp.predict(input_fn=eval_input_func)
new_pred = list(new_predictions)
new_predicted_vals = []

for new_pred in dnn_model_imp.predict(input_fn=eval_input_func):
    new_predicted_vals.append(new_pred['predictions'])
print(new_predicted_vals)
new_mse = mean_squared_error(new_predicted_vals, y_test)
print('Improved Mean Squared Error [DNNRegrssor]: ',new_mse)


# Compare Performance
print('Old Mean Squared Error: ',mse)
print('New Mean Squared Error: ',new_mse)
