# -*- coding: utf-8 -*-
"""BostonDNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/pdhoot16/Machine-Learning/blob/master/BostonDNN.ipynb

<h1>Machine Learning CA2</h1>

---

## **Boston Housing Price Prediction - Neural Network using TensorFlow**

---

## **1. Import Dependencies**
"""

import numpy as np
import pandas as pd
from sklearn.datasets import load_boston
import tensorflow as tf
import matplotlib.pyplot as plt
# %matplotlib inline
import random

"""##  2. Load Dataset"""

boston = load_boston()
print( "type of boston = ", type(boston))

boston.keys()

boston.data.shape

print( boston.feature_names )

print( boston.DESCR )

"""## 3. Seperate Data into Features and Labels and load them as a Pandas Dataframe

### 3.1 Features
"""

features_df = pd.DataFrame(np.array(boston.data), columns=[boston.feature_names])
features_df.head()

"""### 3.2 Labels"""

labels_df = pd.DataFrame(np.array(boston.target), columns=['labels'])
labels_df.head()

"""### 3.3 Combined Data"""

combined_data = pd.concat([features_df,labels_df], axis=1)
combined_data.head()

"""## 4. Train Test Split

### 4.1 Import Library
"""

from sklearn.model_selection import train_test_split

"""### 4.2  Train Test Split
### Training Data = 80% of Dataset
### Test Data = 20% of Dataset
"""

random.seed( 1000 )
X_train, X_test, y_train, y_test = train_test_split(features_df, labels_df, test_size=0.2)

"""## 5. Data Pre-Processing

### 5.1 Import Library
"""

from sklearn.preprocessing import StandardScaler

"""### 5.2 Train Data

### 5.2.1  Define the Preprocessing Method and Fit Training Data to it
"""

scaler = StandardScaler()
scaler.fit(X_train)

"""### 5.2.2. Make X_train to be the Scaled Version of Data
#### This process scales all the values in all 6 columns and replaces them with the new values
"""

X_train = pd.DataFrame(data=scaler.transform(X_train), columns=X_train.columns, index=X_train.index)

"""### 5.2.3. Converting from Pandas Dataframe to Numpy Arrays"""

X_train = np.array(X_train)
y_train = np.array(y_train)

"""### 5.2.4. Get the Type of Training Data"""

type(X_train), type(y_train)

"""### 5.3. Test Data

### 5.3.1 Define the Preprocessing Method and Fit Test Data to it
"""

scal = StandardScaler()
scal.fit(X_test)

"""### 5.3.2. Make X_test to be the Scaled Version of Data
#### This process scales all the values in all columns and replaces them with the new values
"""

X_test = pd.DataFrame(data=scal.transform(X_test), columns=X_test.columns, index=X_test.index)

"""### 5.3.3. Converting from Pandas Dataframe to Numpy Arrays"""

X_test = np.array(X_test)
y_test = np.array(y_test)

"""### 5.3.4. Get the Type of Test Data"""

type(X_test), type(y_test)

"""### 5.4. Define Feature Columns"""

features_df.columns

# Make Feature Columns
feat_cols = [tf.feature_column.numeric_column('x', shape=np.array(X_train).shape[1:])]

"""### 5.5. Define Input Fuction"""

input_func = tf.estimator.inputs.numpy_input_fn({'x':X_train}, y_train, batch_size=1, num_epochs=2000, shuffle=True)

"""### 5.6. Set up Estimator Training Inputs"""

train_input_func = tf.estimator.inputs.numpy_input_fn(X_train, y_train, batch_size=1, num_epochs=1000, shuffle=False)

"""### 5.7. Set up Estimator Test Inputs"""

eval_input_func = tf.estimator.inputs.numpy_input_fn({'x': X_test}, y_test, batch_size=1, num_epochs=1, shuffle=False)

"""## 6. Build Model

### 6.1. Define DNN Regressor Model
"""

dnn_model = tf.estimator.DNNRegressor(hidden_units=[5,3],feature_columns=feat_cols, optimizer='Adam')

"""### 6.2. Train the DNN Regressor Estimator"""

dnn_model.train(input_fn=input_func, steps=2000)

"""## 7. Evaluate the Model"""

dnn_model.evaluate(input_fn=eval_input_func)

"""### 7.1. Predictions"""

predictions = dnn_model.predict(input_fn=eval_input_func)

pred = list(predictions)

"""### 7.2. Get Predicted Values"""

predicted_vals = []

for pred in dnn_model.predict(input_fn=eval_input_func):
    predicted_vals.append(pred['predictions'])

print(predicted_vals)

"""## 8. Performance Evalution

### 8.1 Import Library
"""

from sklearn.metrics import mean_squared_error

"""### 8.2. Calculate the Mean Squared Error"""

mse = mean_squared_error(predicted_vals, y_test)
print('Mean Squared Error [DNNRegrssor]: ',mse)

"""##  9. Improve the Performance by changing Parameters

### 9.1.  Redefine DNN Regressor Model
"""

dnn_model_imp = tf.estimator.DNNRegressor(hidden_units=[10,5,3],feature_columns=feat_cols, optimizer=tf.train.ProximalAdagradOptimizer(
      learning_rate=0.1,l1_regularization_strength=0.001))

"""### 9.2. Re-train the DNN Regressor Estimator"""

dnn_model_imp.train(input_fn=input_func, steps=2000)

"""### 9.3. Re-evaluate the Model"""

dnn_model_imp.evaluate(input_fn=eval_input_func)

"""### 9.4. New Predictions"""

new_predictions = dnn_model_imp.predict(input_fn=eval_input_func)

new_pred = list(new_predictions)

"""### 9.5. New Predicted values"""

new_predicted_vals = []

for new_pred in dnn_model_imp.predict(input_fn=eval_input_func):
    new_predicted_vals.append(new_pred['predictions'])

print(new_predicted_vals)

"""### 9.6. Re-calculate the Mean Squared Error"""

new_mse = mean_squared_error(new_predicted_vals, y_test)
print('Improved Mean Squared Error [DNNRegrssor]: ',new_mse)

"""## 10. Compare Performace"""

print('Old Mean Squared Error: ',mse)
print('New Mean Squared Error: ',new_mse)

import matplotlib.pyplot as plt
# %matplotlib inline
plt.scatter( new_predicted_vals, y_test, s=5 )
plt.xlabel( "Predicted Prices")
plt.ylabel( "Real Prices")
plt.title( "Real vs Predicted Housing Prices")